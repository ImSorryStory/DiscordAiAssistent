# bot_local_qwen.py
# –õ–æ–∫–∞–ª—å–Ω—ã–π Discord voice-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç "–ö–µ–Ω—Ç–∏–∫" (Python 3.12.8)
# –§—É–Ω–∫—Ü–∏–∏: –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ, –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–ª—ã—à–∏–º–æ—Å—Ç–∏, –≥–æ—Ä—è—á–µ–µ —Å–ª–æ–≤–æ "–ö–µ–Ω—Ç–∏–∫",
# –º—É–∑—ã–∫–∞ (yt_dlp), –≤–µ–±-–ø–æ–∏—Å–∫ + –∫—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ (Ollama), TTS (Piper), ASR (faster-whisper)
# –†–µ–∞–ª—Ç–∞–π–º-–ª–æ–≥–∏–∫–∞: –∫–æ—Ä–æ—Ç–∫–∏–µ –æ–∫–Ω–∞ –∑–∞–ø–∏—Å–∏ (~1.2—Å) –±–µ–∑ –≥–æ–Ω–æ–∫, —Ä—É—Å—Å–∫–æ–µ ASR large-v3.
# –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è: —Ä—É—Å—Å–∫–∏–π ASR, –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è .onnx.json, –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –∫–æ–ª–ª–±–µ–∫–∏ –∑–∞–ø–∏—Å–∏,
# –æ–¥–Ω–∞ –∑–∞–ø–∏—Å—å –∑–∞ —Ä–∞–∑ (–Ω–µ—Ç "Already recording"), —Å—Ç–∞–±–∏–ª—å–Ω—ã–π —Ü–∏–∫–ª —Å–ª—É—à–∞–Ω–∏—è, –≥–∞—Ä–∞–Ω—Ç–∏—è –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –≥–æ–ª–æ—Å–æ–≤–æ–º—É.

import os
import io
import re
import asyncio
import tempfile
from collections import deque
from dataclasses import dataclass, field
from typing import Optional, Deque, Dict, List

import requests
from bs4 import BeautifulSoup
from dotenv import load_dotenv

import discord
from discord.ext import commands
from discord.sinks import WaveSink
import yt_dlp

from faster_whisper import WhisperModel

# ========= ENV =========
load_dotenv()
DISCORD_TOKEN = os.getenv("DISCORD_TOKEN")

# ASR (Whisper)
WHISPER_MODEL_NAME = os.getenv("WHISPER_MODEL", "/whisper/faster-whisper-large-v3")
ASR_LANGUAGE = (os.getenv("ASR_LANGUAGE", "ru") or "ru").strip().lower()
_whisper_model: Optional[WhisperModel] = None
_asr_warmed: bool = False

# TTS (Piper)
PIPER_VOICE = os.getenv("PIPER_VOICE")  # –ø—É—Ç—å –∫ .onnx
ESPEAKNG_DATA = os.getenv("ESPEAKNG_DATA")  # –ø—É—Ç—å –∫ espeak-ng-data (–º–æ–∂–Ω–æ –Ω–µ –∑–∞–¥–∞–≤–∞—Ç—å, –µ—Å–ª–∏ —Å–∏—Å—Ç–µ–º–Ω—ã–π)

# LLM (Ollama)
OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "qwen2.5:7b-instruct")
OLLAMA_HOST = os.getenv("OLLAMA_HOST", "http://127.0.0.1:11434")  # –±–µ–∑ /api
OLLAMA_TIMEOUT = float(os.getenv("OLLAMA_TIMEOUT", "120"))

# ========= Discord intents =========
INTENTS = discord.Intents.default()
INTENTS.message_content = True   # –≤–∫–ª—é—á–∏ Message Content Intent –≤ Dev Portal
INTENTS.voice_states = True

bot = commands.Bot(command_prefix="!", intents=INTENTS)

# ========= –ú—É–∑—ã–∫–∞ =========
@dataclass
class Track:
    query: str
    requested_by: Optional[str] = None
    title: Optional[str] = None

@dataclass
class MusicState:
    queue: Deque[Track] = field(default_factory=deque)
    now_playing: Optional[Track] = None

guild_music: Dict[int, MusicState] = {}
assistant_running: Dict[int, bool] = {}

def get_state(guild_id: int) -> MusicState:
    if guild_id not in guild_music:
        guild_music[guild_id] = MusicState()
    return guild_music[guild_id]

YTDLP_OPTS = {
    "format": "bestaudio/best",
    "noplaylist": True,
    "quiet": True,
    "extract_flat": False,
    "default_search": "ytsearch",
    "source_address": "0.0.0.0",
}

def ytdlp_get_source(query: str) -> dict:
    with yt_dlp.YoutubeDL(YTDLP_OPTS) as ydl:
        info = ydl.extract_info(query, download=False)
        if "entries" in info:
            info = info["entries"][0]
        return {"url": info["url"], "title": info.get("title", query)}

async def play_next(ctx: commands.Context):
    state = get_state(ctx.guild.id)
    if not state.queue:
        state.now_playing = None
        return
    track = state.queue.popleft()
    src = ytdlp_get_source(track.query)
    track.title = src.get("title") or track.query
    state.now_playing = track

    vc = ctx.voice_client

    def after_play(_):
        fut = asyncio.run_coroutine_threadsafe(play_next(ctx), bot.loop)
        try:
            fut.result()
        except Exception:
            pass

    ffmpeg_opts = "-nostdin -reconnect 1 -reconnect_streamed 1 -reconnect_delay_max 5"
    vc.play(discord.FFmpegPCMAudio(src["url"], before_options=ffmpeg_opts), after=after_play)
    await ctx.send(f"‚ñ∂Ô∏è **–ò–≥—Ä–∞–µ—Ç:** {track.title}")

# ========= –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ: Voice connect, TTS, ASR, web, LLM =========
async def ensure_voice_connected(ctx: commands.Context) -> Optional[discord.VoiceClient]:
    if ctx.author.voice is None or ctx.author.voice.channel is None:
        await ctx.send("–ó–∞–π–¥–∏ –≤ –≥–æ–ª–æ—Å–æ–≤–æ–π –∫–∞–Ω–∞–ª, –ø–æ—Ç–æ–º –Ω–∞–±–µ—Ä–∏ –∫–æ–º–∞–Ω–¥—É.")
        return None

    vc = ctx.voice_client
    try:
        if vc is None:
            vc = await ctx.author.voice.channel.connect(reconnect=True)
        else:
            if vc.channel != ctx.author.voice.channel:
                await vc.move_to(ctx.author.voice.channel)
    except Exception as e:
        await ctx.send(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –≥–æ–ª–æ—Å–æ–≤–æ–º—É –∫–∞–Ω–∞–ª—É: {e}")
        return None

    # –∂–¥—ë–º –ø–æ–ª–Ω–æ–π –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è (–¥–æ ~6 —Å–µ–∫)
    for _ in range(30):
        if vc and vc.is_connected():
            break
        await asyncio.sleep(0.2)

    if not vc or not vc.is_connected():
        await ctx.send("–ì–æ–ª–æ—Å–æ–≤–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ. –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑ (!join).")
        return None

    return vc


async def speak(vc: discord.VoiceClient, text: str):
    """–û–∑–≤—É—á–∏—Ç—å —Ç–µ–∫—Å—Ç —á–µ—Ä–µ–∑ Piper –∏ –ø—Ä–æ–∏–≥—Ä–∞—Ç—å –≤ –≥–æ–ª–æ—Å–æ–≤–æ–º –∫–∞–Ω–∞–ª–µ."""
    if vc is None or not vc.is_connected():
        raise RuntimeError("–ù–µ—Ç –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è TTS.")

    if not PIPER_VOICE or not os.path.exists(PIPER_VOICE):
        raise RuntimeError(f"PIPER_VOICE –Ω–µ –Ω–∞–π–¥–µ–Ω: {PIPER_VOICE}")
    cfg = PIPER_VOICE + ".json"
    if not os.path.exists(cfg):
        raise RuntimeError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –∫–æ–Ω—Ñ–∏–≥ –º–æ–¥–µ–ª–∏ Piper: {cfg}")

    out_path = tempfile.mktemp(suffix=".wav")

    cmd = ["piper", "--model", PIPER_VOICE, "--output_file", out_path]
    if ESPEAKNG_DATA and os.path.isdir(ESPEAKNG_DATA):
        cmd += ["--espeak-ng-data", ESPEAKNG_DATA]

    # –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ—á—å
    proc = await asyncio.create_subprocess_exec(
        *cmd,
        stdin=asyncio.subprocess.PIPE,
        stdout=asyncio.subprocess.DEVNULL,
        stderr=asyncio.subprocess.PIPE,
    )
    _, err = await proc.communicate(input=text.encode("utf-8"))
    if proc.returncode != 0 or not os.path.exists(out_path):
        raise RuntimeError(f"Piper error: {err.decode(errors='ignore')}")

    # –∂–¥—ë–º, –ø–æ–∫–∞ –æ—Å–≤–æ–±–æ–¥–∏—Ç—Å—è –ø–ª–µ–µ—Ä, –∏ –ø—Ä–æ–∏–≥—Ä—ã–≤–∞–µ–º
    finished = asyncio.Event()
    def _after(_):
        bot.loop.call_soon_threadsafe(finished.set)

    vc.play(discord.FFmpegPCMAudio(out_path), after=_after)
    await finished.wait()

async def _remux_to_clean_wav(raw_bytes: bytes, rate=16000, ch=1) -> bytes:
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –≤—Ö–æ–¥–Ω–æ–µ –∞—É–¥–∏–æ –≤ –≤–∞–ª–∏–¥–Ω—ã–π WAV PCM s16le —á–µ—Ä–µ–∑ ffmpeg."""
    proc = await asyncio.create_subprocess_exec(
        "ffmpeg", "-hide_banner", "-loglevel", "error",
        "-i", "pipe:0",
        "-f", "wav",
        "-ar", str(rate),
        "-ac", str(ch),
        "-acodec", "pcm_s16le",
        "pipe:1",
        stdin=asyncio.subprocess.PIPE,
        stdout=asyncio.subprocess.PIPE,
        stderr=asyncio.subprocess.PIPE,
    )
    out, err = await proc.communicate(input=raw_bytes)
    if proc.returncode != 0 or not out:
        raise RuntimeError(err.decode("utf-8", "ignore") or "ffmpeg remux failed")
    return out

def _ensure_asr_loaded():
    global _whisper_model, _asr_warmed
    if _whisper_model is None:
        # CPU-friendly: int8; –µ—Å–ª–∏ –µ—Å—Ç—å GPU, –º–æ–∂–Ω–æ —Å–º–µ–Ω–∏—Ç—å –Ω–∞ "float16"
        _whisper_model = WhisperModel(WHISPER_MODEL_NAME, device="auto", compute_type="int8")

    # –ü—Ä–æ–≥—Ä–µ–≤ –º–æ–¥–µ–ª–∏ –æ–¥–∏–Ω —Ä–∞–∑ (—É–±–∏—Ä–∞–µ—Ç –ø–µ—Ä–≤—ã–π ¬´—Ñ—Ä–∏–∑¬ª)
    if not _asr_warmed:
        import numpy as np
        import wave
        # 0.5 c —Ç–∏—à–∏–Ω—ã @16kHz mono
        tmp = tempfile.mktemp(suffix=".wav")
        with wave.open(tmp, "wb") as wf:
            wf.setnchannels(1)
            wf.setsampwidth(2)  # s16le
            wf.setframerate(16000)
            wf.writeframes(np.zeros(16000//2, dtype=np.int16).tobytes())
        try:
            list(_whisper_model.transcribe(
                tmp,
                language=ASR_LANGUAGE,
                vad_filter=True,
                vad_parameters={"min_silence_duration_ms": 200, "speech_pad_ms": 200},
                beam_size=1,
                condition_on_previous_text=False,
                temperature=0.0,
            )[0])
        except Exception:
            pass
        _asr_warmed = True

async def asr_transcribe(wav_bytes: bytes) -> str:
    """–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —á–µ—Ä–µ–∑ faster-whisper —Å –±–µ–∑–æ–ø–∞—Å–Ω–æ–π –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π WAV, —è–∑—ã–∫ ‚Äî —Ä—É—Å—Å–∫–∏–π."""
    if len(wav_bytes) < 3000:
        return ""

    _ensure_asr_loaded()

    try:
        clean = await _remux_to_clean_wav(wav_bytes, 16000, 1)
    except Exception:
        return ""

    tmp = tempfile.mktemp(suffix=".wav")
    with open(tmp, "wb") as f:
        f.write(clean)

    segments, _ = _whisper_model.transcribe(
        tmp,
        language=ASR_LANGUAGE,
        vad_filter=True,
        vad_parameters={"min_silence_duration_ms": 200, "speech_pad_ms": 200},
        beam_size=1,  # –±—ã—Å—Ç—Ä–µ–µ, –ø–æ—á—Ç–∏ realtime-—Ä–µ–∂–∏–º
        condition_on_previous_text=False,
        temperature=0.0,
        suppress_tokens="-1",
    )
    return " ".join(s.text.strip() for s in segments).strip()

def ddg_search(query: str, n: int = 3) -> List[dict]:
    url = "https://duckduckgo.com/html/"
    r = requests.post(url, data={"q": query}, timeout=20, headers={"User-Agent": "Mozilla/5.0"})
    r.raise_for_status()
    soup = BeautifulSoup(r.text, "html.parser")
    out = []
    for res in soup.select(".result")[:n]:
        a = res.select_one(".result__a")
        if not a:
            continue
        href = a.get("href")
        title = a.get_text(" ", strip=True)
        sn = res.select_one(".result__snippet")
        out.append({"title": title, "url": href, "snippet": sn.get_text(" ", strip=True) if sn else ""})
    return out

def fetch_and_skim(url: str, max_chars: int = 2500) -> str:
    try:
        html = requests.get(url, timeout=20, headers={"User-Agent": "Mozilla/5.0"}).text
        soup = BeautifulSoup(html, "html.parser")
        for t in soup(["script", "style", "noscript"]):
            t.decompose()
        text = " ".join(soup.get_text(" ").split())
        return text[:max_chars]
    except Exception:
        return ""

def ollama_generate(prompt: str, system: str = "–û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ-—Ä—É—Å—Å–∫–∏.", temperature: float = 0.3) -> str:
    try:
        resp = requests.post(
            f"{OLLAMA_HOST}/api/generate",
            json={
                "model": OLLAMA_MODEL,
                "prompt": f"{system}\n\n{prompt}".strip(),
                "stream": False,
                "options": {"temperature": temperature},
            },
            timeout=OLLAMA_TIMEOUT,
        )
        resp.raise_for_status()
        return resp.json().get("response", "").strip()
    except Exception as e:
        return f"(LLM –æ—à–∏–±–∫–∞: {e})"

def summarize_with_llm(text: str, limit: int = 700) -> str:
    prompt = (
        "–°–¥–µ–ª–∞–π —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ —Ä–µ–∑—é–º–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º, –±–µ–∑ –≤–æ–¥—ã.\n"
        f"–î–æ {limit} —Å–∏–º–≤–æ–ª–æ–≤. –°–æ—Ö—Ä–∞–Ω—è–π –¥–∞—Ç—ã/—Ü–∏—Ñ—Ä—ã.\n\n{text[:6000]}"
    )
    return ollama_generate(prompt)

# ========= –ó–∞–ø–∏—Å—å –∞—É–¥–∏–æ (—É—Ç–∏–ª–∏—Ç—ã) =========
async def start_recording(vc: discord.VoiceClient) -> WaveSink:
    """–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π —Å—Ç–∞—Ä—Ç –∑–∞–ø–∏—Å–∏: –µ—Å–ª–∏ —É–∂–µ –∏–¥—ë—Ç –∑–∞–ø–∏—Å—å ‚Äî –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∏ –∂–¥—ë–º —Å–±—Ä–æ—Å–∞ —Ñ–ª–∞–≥–∞."""
    if vc is None or not vc.is_connected():
        raise RuntimeError("VoiceClient –Ω–µ –ø–æ–¥–∫–ª—é—á—ë–Ω –∫ –≥–æ–ª–æ—Å–æ–≤–æ–º—É –∫–∞–Ω–∞–ª—É.")

    # –ï—Å–ª–∏ –ø–æ –∫–∞–∫–æ–π-—Ç–æ –ø—Ä–∏—á–∏–Ω–µ –µ—â—ë ¬´–∑–∞–ø–∏—Å—ã–≤–∞–µ—Ç¬ª ‚Äî –º—è–≥–∫–æ –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∏ –∂–¥—ë–º.
    if getattr(vc, "recording", False):
        try:
            vc.stop_recording()
        except Exception:
            pass
        for _ in range(20):
            if not getattr(vc, "recording", False):
                break
            await asyncio.sleep(0.05)

    sink = WaveSink()

    # –í–ê–ñ–ù–û: –∫–æ–ª–ª–±–µ–∫ ‚Äî –∫–æ—Ä—É—Ç–∏–Ω–∞
    async def on_stopped(_sink: WaveSink, *_):
        return

    try:
        vc.start_recording(sink, on_stopped)
    except discord.sinks.errors.RecordingException:
        # –ï—â—ë —Ä–∞–∑ —Å—Ç—Ä–∞—Ö–æ–≤–æ—á–Ω–æ —Å—Ç–æ–ø–∞–µ–º –∏ –ø—Ä–æ–±—É–µ–º –ø–æ–≤—Ç–æ—Ä–Ω–æ
        try:
            vc.stop_recording()
        except Exception:
            pass
        await asyncio.sleep(0.1)
        vc.start_recording(sink, on_stopped)

    return sink


async def record_for(vc: discord.VoiceClient, seconds: float) -> Dict[discord.Member, io.BytesIO]:
    """–ó–∞–ø–∏—Å–∞—Ç—å –≥–æ–ª–æ—Å –Ω–∞ N —Å–µ–∫—É–Ω–¥ –∏ –≤–µ—Ä–Ω—É—Ç—å —Å—ã—Ä—ã–µ WAV-–±—É—Ñ–µ—Ä—ã –ø–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º."""
    sink = await start_recording(vc)
    try:
        await asyncio.sleep(seconds)
    finally:
        try:
            vc.stop_recording()
        except Exception:
            pass
        await asyncio.sleep(0.05)

    outputs: Dict[discord.Member, io.BytesIO] = {}
    for user, audio in list(sink.audio_data.items()):
        if getattr(audio, "file", None):
            outputs[user] = io.BytesIO(audio.file.getvalue())
    return outputs

# ========= NLU (–∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ + –ø—Ä–æ—Å—Ç—ã–µ –ø—Ä–∞–≤–∏–ª–∞) =========
KEYWORDS = ["–∫–µ–Ω—Ç", "–∫–µ–Ω—Ç–∏–∫", "–∫–µ–Ω—Ç–µ–∫", "–∫–µ–Ω—Ç—é–∫"]

def extract_after_keyword(text: str) -> str:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ —Å–ª–æ–≤–∞-—Ç—Ä–∏–≥–≥–µ—Ä–∞."""
    t = text.lower()
    for kw in KEYWORDS:
        idx = t.find(kw)
        if idx != -1:
            return text[idx + len(kw):].strip(" ,.:;‚Äî-")
    return ""

def detect_and_handle_intent(text: str) -> dict:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø—Ä–æ—Å—Ç—ã–µ –∏–Ω—Ç–µ–Ω—Ç—ã, –æ–∂–∏–¥–∞—è, —á—Ç–æ text —É–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ."""
    low = text.lower()
    if "–≤–∫–ª—é—á–∏" in low or "–ø–æ—Å—Ç–∞–≤—å" in low or "—Å—ã–≥—Ä–∞–π" in low:
        q = extract_after_keyword(text)
        return {"name": "play_music", "query": q}
    if any(w in low for w in ["–ø–∞—É–∑–∞", "–æ—Å—Ç–∞–Ω–æ–≤–∏"]):
        return {"name": "pause"}
    if any(w in low for w in ["–ø—Ä–æ–¥–æ–ª–∂–∞–π", "–ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å", "resume"]):
        return {"name": "resume"}
    if any(w in low for w in ["—Å–ª–µ–¥—É—é—â–∞—è", "—Å–∫–∏–ø", "–ø—Ä–æ–ø—É—Å—Ç–∏", "next"]):
        return {"name": "skip"}
    if low.startswith("—á—Ç–æ —Ç–∞–∫–æ–µ") or "–Ω–∞–π–¥–∏" in low:
        q = extract_after_keyword(text) or (low.split("–Ω–∞–π–¥–∏", 1)[-1].strip() if "–Ω–∞–π–¥–∏" in low else "")
        return {"name": "web_search", "query": q}
    if any(w in low for w in ["—Å–∫–∞–∂–∏", "–æ–∑–≤—É—á—å", "–ø—Ä–∏–≤–µ—Ç"]):
        msg = extract_after_keyword(text) or "–ü—Ä–∏–≤–µ—Ç! –Ø –Ω–∞ —Å–≤—è–∑–∏."
        return {"name": "say", "text": msg}
    return {"name": "smalltalk", "text": extract_after_keyword(text) or text}

# ========= –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ =========
async def assistant_loop(ctx: commands.Context):
    guild_id = ctx.guild.id
    if assistant_running.get(guild_id):
        await ctx.send("–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç —É–∂–µ –∑–∞–ø—É—â–µ–Ω.")
        return
    assistant_running[guild_id] = True

    # –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º –≥–æ–ª–æ—Å–æ–≤–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ
    vc = await ensure_voice_connected(ctx)
    if vc is None:
        assistant_running[guild_id] = False
        return

    # 1) –ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ
    try:
        await speak(vc, "–í—Å–µ–º –ø—Ä–∏–≤–µ—Ç!")
    except Exception as e:
        await ctx.send(f"(TTS –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏—è –Ω–µ —É–¥–∞–ª–æ—Å—å: {e})")

    # 2) –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–ª—ã—à–∏–º–æ—Å—Ç–∏ (2 —Å–µ–∫)
    try:
        await ctx.send("üéß –ü—Ä–æ–≤–µ—Ä—è—é, —Å–ª—ã—à—É –ª–∏ —è...")
        samples = await record_for(vc, 2.0)
        heard: List[str] = []
        for user, bio in samples.items():
            text = await asr_transcribe(bio.getvalue())
            if text:
                heard.append(f"{user.display_name}: {text}")
        if heard:
            await ctx.send("–°–ª—ã—à—É:\n- " + "\n- ".join(heard[:5]))
        else:
            await ctx.send("–ü–æ—Ö–æ–∂–µ, –Ω–∏–∫—Ç–æ –Ω–∏—á–µ–≥–æ –Ω–µ —Å–∫–∞–∑–∞–ª, –Ω–æ –ø—Ä–æ–¥–æ–ª–∂—É —Å–ª—É—à–∞—Ç—å.")
    except Exception as e:
        await ctx.send(f"(–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–ª—ã—à–∏–º–æ—Å—Ç–∏ –Ω–µ —É–¥–∞–ª–∞—Å—å: {e})")

    await ctx.send("üéô –°–ª—É—à–∞—é. –ì–æ–≤–æ—Ä–∏—Ç–µ **¬´–ö–µ–Ω—Ç–∏–∫ ...¬ª** –∏ –∑–∞—Ç–µ–º –∫–æ–º–∞–Ω–¥—É.")

    # 3) ¬´–ü–æ—á—Ç–∏ realtime¬ª: –∫–æ—Ä–æ—Ç–∫–∏–µ –æ–∫–Ω–∞ –∑–∞–ø–∏—Å–∏ ~1.2—Å
    try:
        while assistant_running.get(guild_id) and vc and vc.is_connected():
            # –ù–µ —Å–ª—É—à–∞–µ–º, –∫–æ–≥–¥–∞ –±–æ—Ç —Å–∞–º —á—Ç–æ-—Ç–æ –æ–∑–≤—É—á–∏–≤–∞–µ—Ç, —á—Ç–æ–±—ã –Ω–µ –ª–æ–≤–∏—Ç—å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π –≥–æ–ª–æ—Å
            if vc.is_playing():
                await asyncio.sleep(0.2)
                continue

            samples = await record_for(vc, 1.2)  # –æ–∫–Ω–æ 1.0‚Äì1.5—Å –¥–∞—ë—Ç –±—ã—Å—Ç—Ä—É—é —Ä–µ–∞–∫—Ü–∏—é
            for user, bio in samples.items():
                wav_bytes = bio.getvalue()
                if len(wav_bytes) < 3000:
                    continue

                text = await asr_transcribe(wav_bytes)
                if not text:
                    continue

                await ctx.send(f"üó£ **{user.display_name}:** {text}")

                # –∫–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ
                low = text.lower()
                if not any(kw in low for kw in KEYWORDS):
                    continue

                intent = detect_and_handle_intent(text)
                name = intent.get("name")

                try:
                    if name == "play_music":
                        q = intent.get("query") or ""
                        get_state(guild_id).queue.append(Track(query=q, requested_by=user.display_name))
                        await ctx.send(f"–î–æ–±–∞–≤–∏–ª –≤ –æ—á–µ—Ä–µ–¥—å: **{q}**")
                        if not vc.is_playing() and not vc.is_paused():
                            await play_next(ctx)

                    elif name == "pause":
                        if vc.is_playing():
                            vc.pause(); await ctx.send("‚è∏ –ü–∞—É–∑–∞")

                    elif name == "resume":
                        if vc.is_paused():
                            vc.resume(); await ctx.send("‚ñ∂Ô∏è –ü—Ä–æ–¥–æ–ª–∂–∏–ª")

                    elif name == "skip":
                        if vc.is_playing() or vc.is_paused():
                            vc.stop(); await ctx.send("‚è≠ –ü—Ä–æ–ø—É—Å—Ç–∏–ª")

                    elif name == "web_search":
                        q = (intent.get("query") or "").strip()
                        if not q:
                            await ctx.send("–ß—Ç–æ –∏–º–µ–Ω–Ω–æ –∏—â–µ–º?")
                            continue
                        await ctx.send(f"üîé –ò—â—É: **{q}**")
                        results = ddg_search(q, n=3)
                        if not results:
                            await ctx.send("–ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞—à—ë–ª.")
                            continue
                        blocks = []
                        for r in results:
                            skim = fetch_and_skim(r["url"], max_chars=2000) if r["url"] else r["snippet"]
                            blocks.append(f"{r['title']}\n{r['url']}\n{skim}")
                        summary = summarize_with_llm("\n\n---\n\n".join(blocks), limit=700)
                        await ctx.send(summary[:1900])
                        try:
                            await speak(vc, summary[:300])
                        except Exception:
                            pass

                    elif name == "say":
                        msg = intent.get("text") or "–î–∞?"
                        await speak(vc, msg)

                    else:  # smalltalk
                        reply = ollama_generate(
                            f"–ö–ª—é—á–µ–≤–æ–µ —Å–ª–æ–≤–æ —É–∂–µ –ø—Ä–æ–∏–∑–Ω–µ—Å–µ–Ω–æ. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–∫–∞–∑–∞–ª: {intent.get('text','')}. –û—Ç–≤–µ—Ç—å –∫–æ—Ä–æ—Ç–∫–æ –∏ –ø–æ –¥–µ–ª—É."
                        )
                        await ctx.send(reply[:1900] if reply else intent.get("text",""))
                        try:
                            await speak(vc, (reply or "–•–æ—Ä–æ—à–æ.")[:300])
                        except Exception:
                            pass

                except Exception as e:
                    await ctx.send(f"(–û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {e})")

            await asyncio.sleep(0.02)

    finally:
        try:
            if ctx.voice_client:
                await stop_recording(ctx.voice_client)
        except Exception:
            pass
        assistant_running[guild_id] = False
        await ctx.send("–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω.")

# ========= –ö–æ–º–∞–Ω–¥—ã =========
@bot.command(name="join")
async def join(ctx: commands.Context):
    vc = await ensure_voice_connected(ctx)
    if vc is None:
        return
    await ctx.send(f"–ü–æ–¥–∫–ª—é—á–∏–ª—Å—è –∫: **{vc.channel.name}**. –ó–∞–ø—É—Å–∫–∞—é –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞‚Ä¶")
    await assistant_loop(ctx)

@bot.command(name="leave")
async def leave(ctx: commands.Context):
    assistant_running[ctx.guild.id] = False
    if ctx.voice_client:
        await stop_recording(ctx.voice_client)
        await ctx.voice_client.disconnect(force=True)
    await ctx.send("–û—Ç–∫–ª—é—á–∏–ª—Å—è.")

@bot.command(name="assistant")
async def assistant(ctx: commands.Context):
    vc = await ensure_voice_connected(ctx)
    if vc is None:
        return
    await assistant_loop(ctx)

@bot.command(name="play")
async def play(ctx: commands.Context, *, query: str):
    if ctx.voice_client is None or not ctx.voice_client.is_connected():
        await ctx.send("–°–Ω–∞—á–∞–ª–∞ !join.")
        return
    get_state(ctx.guild.id).queue.append(Track(query=query, requested_by=str(ctx.author)))
    await ctx.send(f"–î–æ–±–∞–≤–∏–ª –≤ –æ—á–µ—Ä–µ–¥—å: **{query}**")
    if not ctx.voice_client.is_playing() and not ctx.voice_client.is_paused():
        await play_next(ctx)

@bot.command(name="pause")
async def pause(ctx: commands.Context):
    vc = ctx.voice_client
    if vc and vc.is_playing():
        vc.pause(); await ctx.send("‚è∏ –ü–∞—É–∑–∞")

@bot.command(name="resume")
async def resume(ctx: commands.Context):
    vc = ctx.voice_client
    if vc and vc.is_paused():
        vc.resume(); await ctx.send("‚ñ∂Ô∏è –ü—Ä–æ–¥–æ–ª–∂–∏–ª")

@bot.command(name="skip")
async def skip(ctx: commands.Context):
    vc = ctx.voice_client
    if vc and (vc.is_playing() or vc.is_paused()):
        vc.stop(); await ctx.send("‚è≠ –ü—Ä–æ–ø—É—Å—Ç–∏–ª")

@bot.command()
async def recordtest(ctx):
    """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç 5 —Å–µ–∫—É–Ω–¥ –∏–∑ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ, —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç WAV –∏ –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –≤ —á–∞—Ç."""
    if ctx.author.voice is None:
        await ctx.send("–ó–∞–π–¥–∏ –≤ –≥–æ–ª–æ—Å–æ–≤–æ–π –∫–∞–Ω–∞–ª.")
        return

    vc = ctx.voice_client
    if vc is None:
        vc = await ctx.author.voice.channel.connect()

    sink = discord.sinks.WaveSink()

    async def finished_callback(sink: WaveSink, *args):
        for user, audio in sink.audio_data.items():
            wav_path = f"/tmp/{user}.wav"
            with open(wav_path, "wb") as f:
                f.write(audio.file.getvalue())
            await ctx.send(f"–°–æ—Ö—Ä–∞–Ω–∏–ª {user}.wav", file=discord.File(wav_path))
        # –ù–ï –æ—Ç–∫–ª—é—á–∞–µ–º—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏

    vc.start_recording(sink, finished_callback)  # coroutine callback ‚Äî –æ–∫
    await ctx.send("–ó–∞–ø–∏—Å—å 5 —Å–µ–∫—É–Ω–¥... –ì–æ–≤–æ—Ä–∏ —á—Ç–æ-–Ω–∏–±—É–¥—å!")
    await asyncio.sleep(5)
    vc.stop_recording()

@bot.command(name="say")
async def say(ctx: commands.Context, *, text: str):
    vc = await ensure_voice_connected(ctx)
    if vc is None:
        return
    try:
        await speak(vc, text)
        await ctx.send("(–û–∑–≤—É—á–∏–ª)")
    except Exception as e:
        await ctx.send(f"(TTS –æ—à–∏–±–∫–∞: {e})")

@bot.event
async def on_ready():
    try:
        requests.get(f"{OLLAMA_HOST}/api/tags", timeout=3).raise_for_status()
        print(f"Ollama OK ({OLLAMA_MODEL}).")
    except Exception:
        print("‚ö†Ô∏è Ollama –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ó–∞–ø—É—Å—Ç–∏ `ollama serve` –∏–ª–∏ –ø—Ä–æ–≤–µ—Ä—å OLLAMA_HOST.")
    print(f"Logged in as {bot.user} (id={bot.user.id})")

if __name__ == "__main__":
    if not DISCORD_TOKEN:
        raise SystemExit("–ù–µ—Ç DISCORD_TOKEN –≤ .env")
    bot.run(DISCORD_TOKEN)
