# DiscordAiAssistent (Кентик) — локальный голосовой ассистент для Discord

Голосовой бот для Discord с «горячим словом» «Кентик», распознаванием речи (Whisper), синтезом речи (Piper), музыкой с YouTube (yt-dlp), простым веб-поиском и краткими резюме через локальный LLM (Ollama/Qwen). Работает почти в реальном времени короткими окнами записи (~1.2 c), не «подслушивает» самого себя во время озвучки и аккуратно управляет подключением к голосовым каналам. 

---

## Оглавление:
- [Быстрый старт (Docker Compose)](#Быстрый-старт-(Docker-Compose))
- [Возможности](#Возможности)
- [Как пользоваться](#Как-пользоваться)
- [Структура проекта](#Структура-проекта)
- [Стек](#Стек)
- [Как это работает внутри (коротко)](#Как-это-работает-внутри-(коротко))
- [Частые проблемы и решения](#Частые-проблемы-и-решения)
- [Требования (локальный запуск без Docker)](#Требования-(локальный-запуск-без-Docker))
- [Дальнейшие улучшения](#Дальнейшие-улучшения)
---

## Быстрый старт (Docker Compose)
### 1. Подготовьте .env
Создайте файл .env рядом с docker-compose.yml:
```env
DISCORD_TOKEN=ваш_бот_токен_из_Discord_Dev_Portal
# Whisper: путь к модели внутри контейнера бота (или оставьте дефолт)
WHISPER_MODEL=/whisper/faster-whisper-large-v3
ASR_LANGUAGE=ru

# Piper: путь к .onnx (должен лежать в контейнере; рядом нужен .onnx.json)
PIPER_VOICE=/voices/ru_RU/ru_RU-denis-medium.onnx
# Если нужно, укажите системный espeak-ng-data
# ESPEAKNG_DATA=/usr/share/espeak-ng-data

# Ollama: модель и адрес (внутри compose это ollama:11434)
OLLAMA_MODEL=qwen2.5:7b-instruct
OLLAMA_HOST=http://ollama:11434
OLLAMA_TIMEOUT=120
```

> Переменные и их значения по умолчанию берутся в коде бота через dotenv. См. дефолты WHISPER_MODEL, ASR_LANGUAGE, OLLAMA_MODEL, OLLAMA_HOST, OLLAMA_TIMEOUT
 
### 2) Подготовьте голос Piper
Поместите voice-модель .onnx и файл конфигурации с тем же именем плюс .json (например, ru_RU-denis-medium.onnx и ru_RU-denis-medium.onnx.json) в каталог ./voices, а затем примонтируйте его в контейнер:
```yaml
# docker-compose.yml → сервис bot
services:
  bot:
    volumes:
      - ./voices:/voices
```

> Бот проверяет наличие PIPER_VOICE и соответствующего PIPER_VOICE + ".json" и упадёт с понятной ошибкой, если их нет.

### 3) Запустите
```bash
docker compose up -d
```
* Сервис ollama поднимается на 11434/tcp, имеет healthcheck, а сервис bot стартует после того, как Ollama станет «здоров». 
* Для первой работы модели можно выполнить (по желанию):
```bash
docker exec -it ollama ollama pull qwen2.5:7b-instruct 
```
>  Иначе бот сам дождётся, пока модель станет доступной.
* Кэш Hugging Face для whisper-модели сохранится в томе hf_cache, чтобы не качать её заново при каждом запуске. 

> Примечание о GPU: Ollama автоматически использует GPU, если он доступен образу и драйверам. Конфигурация GPU для Docker может отличаться по окружению.

---

## Возможности
- Голосовое управление по ключевому слову «Кентик …» + варианты: кент, кентик, кентек, кентюк. 
- Музыка: поиск и стрим через yt_dlp + FFmpeg с устойчивыми опциями переподключения. 
- Распознавание речи: faster-whisper (по умолчанию русская модель). 
- Озвучка ответов: Piper TTS (проверяется наличие .onnx и соответствующего .onnx.json). 
- Веб-поиск: DuckDuckGo HTML + извлечение текста и краткое резюме через Ollama (по умолчанию qwen2.5:7b-instruct). 
- Команды чата !join, !assistant, !leave, !play, !pause, !resume, !skip, !recordtest, !say. 

---

## Как пользоваться
1. Пригласите бота на сервер, зайдите в голосовой канал и в текстовом канале введите:
```text
!join
```
Бот подключится к вашему голосовому каналу и сразу запустит ассистента (приветствие → быстрая проверка слышимости → постоянное «слушание» короткими окнами). 

2. Дальше говорите голосом команды в голосовом канале:
* «Кентик, включи …» — добавить трек/поиск в очередь. 
* «Кентик, пауза/продолжай/пропусти» — управление плеером. 
* «Кентик, найди …» или «Кентик, что такое …» — веб-поиск и краткое резюме (бот и проговорит, и пришлёт текст). 
* «Кентик, скажи …» — озвучит ваш текст через Piper. 
* Полезные команды в чате:
-- !assistant — вручную запустить голосовой цикл, если вы уже подключены. 
-- !play <запрос> — добавить трек в очередь. 
-- !pause, !resume, !skip — управление воспроизведением. 
-- !recordtest — записать 5 секунд и прислать WAV-файл в чат (для диагностики). 
-- !say <текст> — озвучить текст в голосовом канале. 
-- !leave — остановить ассистента и отключиться.

---

## Структура проекта:
.   
├─ bot_local_qwen.py        # основной код бота   
├─ docker-compose.yml       # оркестрация: ollama + бот   
├─ Dockerfile               # окружение бота (зависимости, ffmpeg, piper и т.п.)   
├─ .env                     # настройки   
└─ voices/                  # модели Piper (.onnx + .onnx.json), если монтируете с хоста   
> См. bot_local_qwen.py и docker-compose.yml для точных деталей.

---

## Стек
- Python 3.12 (discord.py, yt_dlp, python-dotenv, requests, beautifulsoup4, faster-whisper) — логика бота. 
- FFmpeg — запись/перегон аудио в WAV s16le 16 kHz mono. 
- Piper — синтез речи из текста. Проверяется модель .onnx и конфиг *.onnx.json. 
- Ollama + Qwen — локальный LLM для суммаризации/малого NLU. 
- Docker Compose — быстрый запуск всего окружения, отдельные тома под кэш HF и модели Ollama. 

---

## Как это работает внутри (коротко)
* Voice I/O: запись короткими окнами (~1.2 c) через discord.sinks.WaveSink; во время собственной озвучки бот не слушает, чтобы не ловить свой голос. 
* ASR: входной звук приводится в чистый WAV s16le 16 kHz mono через ffmpeg, затем транскрибируется faster-whisper (RU). Есть одноразовый «прогрев» модели, чтобы убрать первый фриз. 
* TTS: текст синтезируется Piper и проигрывается через FFmpeg, есть ожидание конца проигрывания. 
* Музыка: yt_dlp вытаскивает прямой URL, FFmpeg играет с флагами реконнекта, очередь треков управляется сообщениями. 
* Web+LLM: DuckDuckGo HTML выдача → короткий «ским» текстов → суммаризация Ollama (OLLAMA_MODEL). 

---

## Частые проблемы и решения
* Piper error / нет .onnx.json: проверьте, что рядом с моделью PIPER_VOICE=/voices/...onnx лежит файл ...onnx.json. Иначе TTS упадёт с явным сообщением. 
* Whisper долго стартует/качается заново: кэш HF вынесен в том hf_cache. Оставьте его между перезапусками. 
* Ollama недоступен: при старте бот пишет предупреждение и продолжает работу, но функции LLM/суммаризации работать не будут — убедитесь, что сервис ollama запущен и доступен. 
* !leave падает на stop_recording(...): в исходнике есть вызов await stop_recording(ctx.voice_client), а отдельной функции stop_recording не определено. Временный обход — закомментируйте строку либо замените на безопасный вызов try: ctx.voice_client.stop_recording() except: pass перед disconnect(). 

---

## Требования (локальный запуск без Docker)
Python 3.12; зависимости: discord.py (с голосом), yt_dlp, python-dotenv, requests, beautifulsoup4, faster-whisper. FFmpeg должен быть в PATH. Piper — установлен в систему. Параметры (WHISPER_MODEL, ASR_LANGUAGE, PIPER_VOICE, OLLAMA_*) задаются через .env. 

---

## Дальнейшие улучшения
* Радио: Поиск и воспроизведение музыки по жанру/настроение/эпохе
* Запоминание голосов: Выделение и анализ голоса с привязкой к имени пользователя, а также ответ на вопросы с оброщением по имени


